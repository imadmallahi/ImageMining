{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import ntpath \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import mahotas\n",
    "import os\n",
    "import pickle \n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_moments(pic):\n",
    "    pic=np.double(pic)\n",
    "    R=pic[:,:,0]\n",
    "    G=pic[:,:,1]\n",
    "    B=pic[:,:,2]\n",
    "    colorFeature=[np.mean(R[:]),np.std(R[:]),np.mean(G[:]),np.std(G[:]),np.mean(B[:]),np.std(B[:])];\n",
    "    colorFeature=colorFeature/np.mean(colorFeature)\n",
    "    return colorFeature\n",
    "\n",
    "def shapeFeatures(pic):\n",
    "     # Calculate Moments\n",
    "     moments = cv2.moments(cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY))\n",
    "     # Calculate Hu Moments\n",
    "     huMoments = cv2.HuMoments(moments).flatten()\n",
    "     shapeFeat=huMoments/np.mean(huMoments);\n",
    "     return shapeFeat\n",
    "\n",
    "# feature-descriptor-2: histogram\n",
    "def fd_histogram(pic):\n",
    "    # convert the image to HSV color-space\n",
    "    pic = cv2.cvtColor(pic, cv2.COLOR_BGR2HSV)\n",
    "    # compute the color histogram\n",
    "    hist  = cv2.calcHist(pic, [0, 1, 2], None, [8, 2, 2], [0, 256, 0, 256, 0, 256])\n",
    "    # normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    # return the histogram\n",
    "    return hist.flatten()\n",
    "\n",
    "# feature-descriptor-2: Haralick Texture\n",
    "def fd_haralick(pic):\n",
    "    # convert the image to grayscale\n",
    "    gray = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY)\n",
    "    # compute the haralick texture feature vector\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    # return the result\n",
    "    return haralick\n",
    " \n",
    "def getFeatures(pic):\n",
    "    featuresGlbal=np.zeros((209,30))\n",
    "    fv_Moments=color_moments(pic)\n",
    "    fv_histogram  = fd_histogram(pic)\n",
    "    fv_haralick= fd_haralick(pic)\n",
    "    fv_hu_moments = shapeFeatures(pic);\n",
    "    \n",
    "    #featuresGlbal= np.append(fv_haralick, fv_histogram);\n",
    "    \n",
    "    features = np.append(fv_Moments, fv_haralick);\n",
    "    features = np.append(features, fv_hu_moments);\n",
    "    featuresGlbal = np.append(features, fv_histogram);\n",
    "    return featuresGlbal\n",
    "    \n",
    "def createFeatures(fold1,fold2):\n",
    "    dircs1 = os.listdir(fold1)\n",
    "    dircs2 = os.listdir(fold1)\n",
    "    \n",
    "    with open('featuresTrain.csv', 'w') as out:\n",
    "        for dirc in dircs1:\n",
    "            for pic in glob.glob(fold1+'\\\\'+dirc+'\\\\*.jpg'):\n",
    "                img = cv2.resize(cv2.imread(pic),None, fx = 0.1, fy = 0.1)\n",
    "                feats = np.append(dirc,getFeatures(img))\n",
    "                out.write('%s\\n'% ','.join(feats))\n",
    "                \n",
    "    with open('featuresValidation.csv', 'w') as out:\n",
    "        for dirc in dircs2:\n",
    "            for pic in glob.glob(fold2+'\\\\'+dirc+'\\\\*.jpg'):\n",
    "                img = cv2.resize(cv2.imread(pic),None, fx = 0.1, fy = 0.1)\n",
    "                feats = np.append(dirc,getFeatures(img))\n",
    "                out.write('%s\\n'% ','.join(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "createFeatures('train','validation')\n",
    "    \n",
    "data = pd.read_csv('featuresTrain.csv', sep = ',').to_numpy()\n",
    "x_train = data[:,1:]\n",
    "y_train = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(.3) \n",
    "pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)\n",
    "    \n",
    "#lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "#x_train = lda.fit(x_train, y_train).transform(x_train)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score de training with SVC : 0.6906077348066298\n"
     ]
    }
   ],
   "source": [
    "#    #Build your classifier KNN\n",
    "    #classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "# Build your classifier SVM\n",
    "classifier = SVC(kernel='rbf',gamma=0.4)\n",
    "    \n",
    "# Save the trained model as a pickle string. \n",
    "saved_model = pickle.dumps(classifier)\n",
    "    \n",
    "# Load the pickled model \n",
    "classifier_from_pickle = pickle.loads(saved_model)\n",
    "\n",
    "# fit model\n",
    "classifier_from_pickle.fit(x_train,y_train)\n",
    "print('score de training with SVC :',classifier_from_pickle.score(x_train,y_train))\n",
    "\n",
    "data3 = pd.read_csv('featuresValidation.csv', sep = ',').to_numpy()\n",
    "x_validation = data3[:,1:]\n",
    "y_validation = data3[:,0] \n",
    "\n",
    "scaler.fit(x_validation)\n",
    "x_validation = scaler.transform(x_validation)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-46-338c3ca4a5d2>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-46-338c3ca4a5d2>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    x_validation = lda.transform(x_validation)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#    pca.fit(x_validation)\n",
    "#    x_validation = pca.transform(x_validation)\n",
    "    \n",
    "x_validation = lda.transform(x_validation)\n",
    "\n",
    "print('score de validation:',classifier_from_pickle.score(x_validation,y_validation))\n",
    "\n",
    "x_test = []\n",
    "y_pred = []\n",
    "for pic in glob.glob(\"test\\\\*.jpg\"):\n",
    "    x_test.append(ntpath.basename(pic))\n",
    "    feature = getFeatures(cv2.imread(pic))\n",
    "    # noramlize\n",
    "    feature = feature.reshape(1,-1)\n",
    "    scaler.fit(feature)\n",
    "    feature = scaler.transform(feature)\n",
    "    # pca\n",
    "#        pca.fit(feature)\n",
    "#        feature = pca.transform(feature)\n",
    "\n",
    "    feature = lda.transform(feature)\n",
    "    print(classifier_from_pickle.predict(feature))\n",
    "    y_pred.append('Plante_'+classifier_from_pickle.predict(feature)[0]) \n",
    "\n",
    "r= pd.DataFrame({'name':x_test,'classe':y_pred})\n",
    "r.to_csv(\"resultat.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
