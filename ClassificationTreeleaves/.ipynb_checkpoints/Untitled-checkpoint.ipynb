{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import imageio\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage import color\n",
    "from skimage.feature.texture import greycoprops,greycomatrix\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(path,i,title):\n",
    "    img = cv2.imread(path)\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hsvHistogramFeatures(img):\n",
    "\trows, cols, numOfBands = img.shape[:]\n",
    "\timg = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\th = img[:,:,0]\n",
    "\ts = img[:,:,1]\n",
    "\tv = img[:,:,2]\n",
    "\tnumberOfLevelsForH = 8 \n",
    "\tnumberOfLevelsForS = 2 \n",
    "\tnumberOfLevelsForV = 2 \n",
    "\tmaxValueForH = np.max(h)\n",
    "\tmaxValueForS = np.max(s)\n",
    "\tmaxValueForV = np.max(v)\n",
    "\thsvColor_Histogram = np.zeros((8, 2, 2))\n",
    "\tquantizedValueForH = np.ceil( h.dot(numberOfLevelsForH) / maxValueForH)\n",
    "\tquantizedValueForS = np.ceil( s.dot(numberOfLevelsForS) / maxValueForS)\n",
    "\tquantizedValueForV = np.ceil( v.dot(numberOfLevelsForV) / maxValueForV)\n",
    "\tindex = np.zeros((rows*cols, 3))\n",
    "\t#print(quantizedValueForH.shape[0] * quantizedValueForH.shape[1])\n",
    "\tindex[:,0] = quantizedValueForH.reshape(1,-1).reshape(1,quantizedValueForH.shape[0] * quantizedValueForH.shape[1]) \n",
    "\tindex[:,1] = quantizedValueForS.reshape(1,-1).reshape(1,quantizedValueForS.shape[0] * quantizedValueForS.shape[1]) \n",
    "\tindex[:,2] = quantizedValueForV.reshape(1,-1).reshape(1,quantizedValueForV.shape[0] * quantizedValueForV.shape[1])\n",
    "\tk=0\n",
    "\tfor row in range(len(index[:,0])):\n",
    "\t\tif index[row,0] == 0 or index[row,1] == 0 or index[row,2] == 0:\n",
    "\t\t\tk+=1\n",
    "\t\t\tcontinue\n",
    "\t\thsvColor_Histogram[int(index[row,0])-1,int(index[row,1])-1,int(index[row,2])-1] = hsvColor_Histogram[int(index[row,0])-1,int(index[row,1])-1,int(index[row,2])-1] + 1\n",
    "\t#print(k,index[:,0].shape)\n",
    "\thsvColor_Histogram = hsvColor_Histogram[:].reshape(1,-1)\n",
    "\thsvColor_Histogram = hsvColor_Histogram/np.sum(hsvColor_Histogram)\n",
    "\treturn hsvColor_Histogram.reshape(-1)\n",
    "\n",
    "def extractColorFeature(img):\n",
    "    R = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    B = img[:,:,2]\n",
    "    features = [np.mean(R),np.std(R),np.mean(G),np.std(G),np.mean(B),np.std(B)]\n",
    "    features/=np.mean(features)\n",
    "    return features\n",
    "\n",
    "def textureFeatures(img):\n",
    "    img = color.rgb2gray(img)\n",
    "    img = skimage.img_as_ubyte(img)\n",
    "    glcm = greycomatrix(img, [1], [0], 256, symmetric=True, normed=True)\n",
    "    feature = greycoprops(glcm, 'dissimilarity')[0]\n",
    "    feature = np.concatenate([feature,greycoprops(glcm, 'correlation')[0]])\n",
    "    feature = np.concatenate([feature,greycoprops(glcm, 'contrast')[0]])\n",
    "    feature = np.concatenate([feature,greycoprops(glcm, 'energy')[0]])\n",
    "    feature = feature/np.sum(feature)\n",
    "    #print(feature)\n",
    "    return feature\n",
    "\n",
    "def shapeFeatures(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    _,img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
    "    feature = cv2.HuMoments(cv2.moments(img))\n",
    "    return feature.reshape(-1)\n",
    "\n",
    "def getFeatures(img,featuresSize):\n",
    "\tif featuresSize >= 7 :\n",
    "\t\tfeatures = extractColorFeature(img)\n",
    "\tif featuresSize >= 39 :\n",
    "\t\tfeatures = np.concatenate([features, hsvHistogramFeatures(img)])\n",
    "\tif featuresSize >= 43:\n",
    "\t\tfeatures = np.concatenate([features, textureFeatures(img)])\n",
    "\tif featuresSize >= 50:\n",
    "\t\tfeatures = np.concatenate([features, shapeFeatures(img)])\n",
    "\t#print(features)\n",
    "\treturn features\n",
    "\n",
    "\n",
    "def extractAllFeatures(files,fsize,mode = 1):\n",
    "\tif mode == 1:\n",
    "\t\tv = []\n",
    "\t\tfor f in files:\n",
    "\t\t\timg = cv2.imread(f)\n",
    "\t\t\tv.append(getFeatures(cv2.cvtColor(img, cv2.COLOR_BGR2RGB),fsize))\t\n",
    "\t\tnp.save('features.npy',v,allow_pickle=True)\n",
    "\telse :\n",
    "\t\tv = np.load('features.npy',allow_pickle=True)\n",
    "\treturn v\n",
    "def CBIR_Search(features, image_req,fsize):\n",
    "\tfeature_req = getFeatures(image_req,fsize)\n",
    "\tdist = []\n",
    "\tfor feature in features:\n",
    "\t\tdist.append(euclidien_distance(feature,feature_req))\n",
    "\tdist = np.argsort(dist)[:5].tolist()\n",
    "\treturn dist\n",
    "\n",
    "def euclidien_distance(A,B):\n",
    "\tdist = (A - B)**2\n",
    "\tdist = np.sum(dist,axis = 0)\n",
    "\treturn np.sqrt(dist)\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "\timages_path = '../../Atelier_1/obj_decoys'\n",
    "\tfsize = 50\n",
    "\tfiles = [os.path.join(images_path,p) for p in sorted(os.listdir(images_path))]\n",
    "\tfeatures = extractAllFeatures(files,fsize,1) # 0 if you already have the features.npy(second time to run the code) , 1 id the first time you run this code\n",
    "\timage_req_path = '../../Atelier_1/ImageRequete.jpg'\n",
    "\timage_req = cv2.cvtColor(cv2.imread(image_req_path), cv2.COLOR_BGR2RGB)\n",
    "\tdist = CBIR_Search(features,image_req,fsize)\n",
    "\tshow_img(image_req_path,1,'Request Image')\n",
    "\tfor i in range(5):\n",
    "\t\tshow_img(files[dist[i]],i+2,'Result Image '+ str(i+1))\n",
    "\tplt.show()\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malade\n",
      "saine\n"
     ]
    }
   ],
   "source": [
    "with open('vect_feats.csv', 'w') as out:\n",
    "    for root, dirs, files in os.walk(\"train\"):\n",
    "        for d in dirs :\n",
    "            print(d)\n",
    "            if d == 'malade':\n",
    "                target = 0\n",
    "            else :\n",
    "                target=1\n",
    "            for rr,dd,ff in os.walk(\"train/\"+d):\n",
    "                for f in ff:\n",
    "                    img = cv2.imread('train/'+str(d)+'/'+f)\n",
    "                    #img = cv2.resize(img, None, fx = 0.1, fy = 0.1)\n",
    "                    feats = getFeatures(img,40 )\n",
    "                    feats = np.concatenate([[f],feats])\n",
    "                    feats = np.concatenate([[target],feats])\n",
    "                    out.write('%s\\n'% ','.join(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"vect_feats.csv\", sep = ',').to_numpy()\n",
    "names = data[:,1]\n",
    "Y_train= data[:,0].astype('int')\n",
    "X_train = data[:,2:]\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=10)\n",
    "X_lda = lda.fit(X_train, Y_train).transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf=svm.SVC(C=3.0,kernel='rbf',gamma=0.4)\n",
    "clf1=svm.SVC(C=1.0,kernel='rbf',gamma='scale')\n",
    "model=clf.fit(X_pca,Y_train) \n",
    "model1=clf1.fit(X_lda,Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malade\n",
      "saine\n"
     ]
    }
   ],
   "source": [
    "with open('vect_feats_validation.csv', 'w') as out:\n",
    "    for root, dirs, files in os.walk(\"validation\"):\n",
    "        for d in dirs :\n",
    "            print(d)\n",
    "            if d == 'malade':\n",
    "                target = 0\n",
    "            else :\n",
    "                target=1\n",
    "            for rr,dd,ff in os.walk(\"validation/\"+d):\n",
    "                for f in ff:\n",
    "                    img = cv2.imread('validation/'+str(d)+'/'+f)\n",
    "                    #img = cv2.resize(img, None, fx = 0.1, fy = 0.1)\n",
    "                    feats = getFeatures(img, 40)\n",
    "                    feats = np.concatenate([[f],feats])\n",
    "                    feats = np.concatenate([[target],feats])\n",
    "                    out.write('%s\\n'% ','.join(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"vect_feats_validation.csv\", sep = ',').to_numpy()\n",
    "names_valid = data1[:,1]\n",
    "Y_valid= data1[:,0].astype('int')\n",
    "X_valid = data1[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "X_valid_pca = pca.fit_transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=10)\n",
    "X_valid_lda = lda.fit(X_valid, Y_valid).transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_pca=model.predict(X_valid_pca)\n",
    "Y_pred_lda=model1.predict(X_valid_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM  accuracy  PCA  63.46153846153846 %\n",
      " SVM  accuracy  LDA  100.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(' SVM  accuracy  PCA ',accuracy_score(Y_pred_pca,Y_valid)*100,'%')\n",
    "print(' SVM  accuracy  LDA ',accuracy_score(Y_pred_lda,Y_valid)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "tn, fp, fn, tp=confusion_matrix(Y_pred_pca,Y_valid).ravel()\n",
    "precision,recall,fscore,support= precision_recall_fscore_support(Y_valid, Y_pred_pca, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN : 17\n",
      "TP : 16\n",
      "FN : 15\n",
      "FP : 4\n",
      "precision : [0.80952381 0.51612903]\n",
      "recall [0.53125 0.8    ]\n",
      "fscore [0.64150943 0.62745098]\n",
      "support [32 20]\n"
     ]
    }
   ],
   "source": [
    "print('TN :',tn)\n",
    "print('TP :',tp)\n",
    "print('FN :',fn)\n",
    "print('FP :',fp)\n",
    "print('precision :',precision)\n",
    "print('recall',recall)\n",
    "print('fscore',fscore)\n",
    "print('support',support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN : 17\n",
      "TP : 16\n",
      "FN : 15\n",
      "FP : 4\n",
      "precision : [1. 1.]\n",
      "recall [1. 1.]\n",
      "fscore [1. 1.]\n",
      "support [32 20]\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp=confusion_matrix(Y_pred_pca,Y_valid).ravel()\n",
    "precision,recall,fscore,support= precision_recall_fscore_support(Y_valid, Y_pred_lda, average=None)\n",
    "\n",
    "print('TN :',tn)\n",
    "print('TP :',tp)\n",
    "print('FN :',fn)\n",
    "print('FP :',fp)\n",
    "print('precision :',precision)\n",
    "print('recall',recall)\n",
    "print('fscore',fscore)\n",
    "print('support',support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vect_feats_test.csv', 'w') as out:\n",
    "    for root, dirs, files in os.walk(\"test\"):\n",
    "        for d in dirs :\n",
    "            print(d)\n",
    "            if d == 'malade':\n",
    "                target = 0\n",
    "            else :\n",
    "                target=1\n",
    "            for rr,dd,ff in os.walk(\"test/\"+d):\n",
    "                for f in ff:\n",
    "                    img = cv2.imread('test/'+str(d)+'/'+f)\n",
    "                    #img = cv2.resize(img, None, fx = 0.1, fy = 0.1)\n",
    "                    feats = getFeatures(img, 40)\n",
    "                    feats = np.concatenate([[f],feats])\n",
    "                    feats = np.concatenate([[target],feats])\n",
    "                    out.write('%s\\n'% ','.join(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
