{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import imageio\n",
    "import csv\n",
    "import joblib\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage import color\n",
    "from skimage.feature.texture import greycoprops,greycomatrix\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(path,i,title):\n",
    "    img = cv2.imread(path)\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "def hsvHistogramFeatures(img):\n",
    "\trows, cols, numOfBands = img.shape[:]\n",
    "\timg = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\th = img[:,:,0]\n",
    "\ts = img[:,:,1]\n",
    "\tv = img[:,:,2]\n",
    "\tnumberOfLevelsForH = 8 \n",
    "\tnumberOfLevelsForS = 2 \n",
    "\tnumberOfLevelsForV = 2 \n",
    "\tmaxValueForH = np.max(h)\n",
    "\tmaxValueForS = np.max(s)\n",
    "\tmaxValueForV = np.max(v)\n",
    "\thsvColor_Histogram = np.zeros((8, 2, 2))\n",
    "\tquantizedValueForH = np.ceil( h.dot(numberOfLevelsForH) / maxValueForH)\n",
    "\tquantizedValueForS = np.ceil( s.dot(numberOfLevelsForS) / maxValueForS)\n",
    "\tquantizedValueForV = np.ceil( v.dot(numberOfLevelsForV) / maxValueForV)\n",
    "\tindex = np.zeros((rows*cols, 3))\n",
    "\t#print(quantizedValueForH.shape[0] * quantizedValueForH.shape[1])\n",
    "\tindex[:,0] = quantizedValueForH.reshape(1,-1).reshape(1,quantizedValueForH.shape[0] * quantizedValueForH.shape[1]) \n",
    "\tindex[:,1] = quantizedValueForS.reshape(1,-1).reshape(1,quantizedValueForS.shape[0] * quantizedValueForS.shape[1]) \n",
    "\tindex[:,2] = quantizedValueForV.reshape(1,-1).reshape(1,quantizedValueForV.shape[0] * quantizedValueForV.shape[1])\n",
    "\tk=0\n",
    "\tfor row in range(len(index[:,0])):\n",
    "\t\tif index[row,0] == 0 or index[row,1] == 0 or index[row,2] == 0:\n",
    "\t\t\tk+=1\n",
    "\t\t\tcontinue\n",
    "\t\thsvColor_Histogram[int(index[row,0])-1,int(index[row,1])-1,int(index[row,2])-1] = hsvColor_Histogram[int(index[row,0])-1,int(index[row,1])-1,int(index[row,2])-1] + 1\n",
    "\t#print(k,index[:,0].shape)\n",
    "\thsvColor_Histogram = hsvColor_Histogram[:].reshape(1,-1)\n",
    "\thsvColor_Histogram = hsvColor_Histogram/np.sum(hsvColor_Histogram)\n",
    "\treturn hsvColor_Histogram.reshape(-1)\n",
    "\n",
    "def extractColorFeature(img):\n",
    "    R = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    B = img[:,:,2]\n",
    "    features = [np.mean(R),np.std(R),np.mean(G),np.std(G),np.mean(B),np.std(B)]\n",
    "    features/=np.mean(features)\n",
    "    return features\n",
    "\n",
    "def textureFeatures(img):\n",
    "    img = color.rgb2gray(img)\n",
    "    img = skimage.img_as_ubyte(img)\n",
    "    glcm = greycomatrix(img, [1], [0], 256, symmetric=True, normed=True)\n",
    "    feature = greycoprops(glcm, 'dissimilarity')[0]\n",
    "    feature = np.concatenate([feature,greycoprops(glcm, 'correlation')[0]])\n",
    "    feature = np.concatenate([feature,greycoprops(glcm, 'contrast')[0]])\n",
    "    feature = np.concatenate([feature,greycoprops(glcm, 'energy')[0]])\n",
    "    feature = feature/np.sum(feature)\n",
    "    #print(feature)\n",
    "    return feature\n",
    "\n",
    "def shapeFeatures(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    _,img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
    "    feature = cv2.HuMoments(cv2.moments(img))\n",
    "    return feature.reshape(-1)\n",
    "\n",
    "def getFeatures(img,featuresSize):\n",
    "\tif featuresSize >= 7 :\n",
    "\t\tfeatures = extractColorFeature(img)\n",
    "\tif featuresSize >= 39 :\n",
    "\t\tfeatures = np.concatenate([features, hsvHistogramFeatures(img)])\n",
    "\tif featuresSize >= 43:\n",
    "\t\tfeatures = np.concatenate([features, textureFeatures(img)])\n",
    "\tif featuresSize >= 50:\n",
    "\t\tfeatures = np.concatenate([features, shapeFeatures(img)])\n",
    "\t#print(features)\n",
    "\treturn features\n",
    "\n",
    "\n",
    "def extractAllFeatures(files,fsize,mode = 1):\n",
    "\tif mode == 1:\n",
    "\t\tv = []\n",
    "\t\tfor f in files:\n",
    "\t\t\timg = cv2.imread(f)\n",
    "\t\t\tv.append(getFeatures(cv2.cvtColor(img, cv2.COLOR_BGR2RGB),fsize))\t\n",
    "\t\tnp.save('features.npy',v,allow_pickle=True)\n",
    "\telse :\n",
    "\t\tv = np.load('features.npy',allow_pickle=True)\n",
    "\treturn v\n",
    "def CBIR_Search(features, image_req,fsize):\n",
    "\tfeature_req = getFeatures(image_req,fsize)\n",
    "\tdist = []\n",
    "\tfor feature in features:\n",
    "\t\tdist.append(euclidien_distance(feature,feature_req))\n",
    "\tdist = np.argsort(dist)[:5].tolist()\n",
    "\treturn dist\n",
    "\n",
    "def euclidien_distance(A,B):\n",
    "\tdist = (A - B)**2\n",
    "\tdist = np.sum(dist,axis = 0)\n",
    "\treturn np.sqrt(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 254]\n",
      " [255 255 254]\n",
      " [255 255 254]\n",
      " ...\n",
      " [255 255 255]\n",
      " [255 255 255]\n",
      " [255 255 255]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "caract = []\n",
    "X=[]\n",
    "path = os.listdir('training/')\n",
    "for label in path:\n",
    "    k=0\n",
    "    for name in os.listdir('training/'+label):\n",
    "        if k <2:#segmentation d'une image 1 \n",
    "            img = cv2.imread('training/'+label+'/'+name)           \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    X.append(img[i,j])\n",
    "                    caract.append(img[i,j,:].mean())\n",
    "                    caract.append(img[i,j,:].std() )\n",
    "        k+=1\n",
    "caract = np.array(caract)\n",
    "caract = caract.reshape(int(caract.shape[0]/2),2)\n",
    "\n",
    "print(np.array(X))\n",
    "kmean = KMeans(n_clusters=2)\n",
    "kmean.fit(X)\n",
    "labels = kmean.labels_.reshape(400,200)\n",
    "labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vect_feats.csv', 'w') as out:\n",
    "    k=0\n",
    "    for root, dirs, files in os.walk(\"training\"):\n",
    "        for d in dirs :\n",
    "            k=k+1\n",
    "            for rr,dd,ff in os.walk(\"training/\"+d):\n",
    "                for f in ff:\n",
    "                    img = cv2.imread('training/'+str(d)+'/'+f)                    \n",
    "                    feats = getFeatures(img,50 )\n",
    "                    feats = np.concatenate([[f],feats])\n",
    "                    feats = np.concatenate([[d],feats])\n",
    "                    feats = np.concatenate([[k],feats])\n",
    "                    out.write('%s\\n'% ','.join(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"vect_feats.csv\", sep = ',').to_numpy()\n",
    "names = data[:,1]\n",
    "Y_train= data[:,0].astype('int')\n",
    "X_train = data[:,3:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modele_apprentissage_SVM.sav']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf=svm.SVC(gamma='scale')\n",
    "\n",
    "model=clf.fit(X_train,Y_train) \n",
    "fname = 'modele_apprentissage_SVM.sav'\n",
    "joblib.dump(model, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:135: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "with open('vect_feats_validation.csv', 'w') as out:\n",
    "    k=0\n",
    "    for root, dirs, files in os.walk(\"validation\"):\n",
    "        for d in dirs :\n",
    "            k=k+1\n",
    "            for rr,dd,ff in os.walk(\"validation/\"+d):\n",
    "                for f in ff:\n",
    "                    img = cv2.imread('validation/'+str(d)+'/'+f)\n",
    "                    #img = cv2.resize(img, None, fx = 0.1, fy = 0.1)\n",
    "                    feats = getFeatures(img, 50)\n",
    "                    feats = np.concatenate([[f],feats])\n",
    "                    feats = np.concatenate([[d],feats])\n",
    "                    feats = np.concatenate([[k],feats])\n",
    "                    out.write('%s\\n'% ','.join(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"vect_feats_validation.csv\", sep = ',').to_numpy()\n",
    "names_valid = data1[:,1]\n",
    "Y_valid= data1[:,0].astype('int')\n",
    "X_valid = data1[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_valid=model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM  accuracy  100.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(' SVM  accuracy ',accuracy_score(Y_pred_valid,Y_valid)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[163   0   0   0]\n",
      " [  0 164   0   0]\n",
      " [  0   0 143   0]\n",
      " [  0   0   0 163]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print(confusion_matrix(Y_pred_valid,Y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100_100.jpg\n",
      "101_100.jpg\n",
      "102_100.jpg\n",
      "103_100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:135: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104_100.jpg\n",
      "105_100.jpg\n",
      "106_100.jpg\n",
      "12_100.jpg\n",
      "167_100.jpg\n",
      "168_100.jpg\n",
      "169_100.jpg\n",
      "170_100.jpg\n",
      "171_100.jpg\n",
      "172_100.jpg\n",
      "173_100.jpg\n",
      "174_100.jpg\n",
      "175_100.jpg\n",
      "176_100.jpg\n",
      "177_100.jpg\n",
      "178_100.jpg\n",
      "179_100.jpg\n",
      "17_100.jpg\n",
      "181_100.jpg\n",
      "182_100.jpg\n",
      "183_100.jpg\n",
      "184_100.jpg\n",
      "185_100.jpg\n",
      "186_100.jpg\n",
      "187_100.jpg\n",
      "188_100.jpg\n",
      "205_100.jpg\n",
      "20_100.jpg\n",
      "212_100.jpg\n",
      "217_100.jpg\n",
      "21_100.jpg\n",
      "220_100.jpg\n",
      "22_100.jpg\n",
      "23_100.jpg\n",
      "24_100.jpg\n",
      "25_100.jpg\n",
      "26_100.jpg\n",
      "27_100.jpg\n",
      "28_100.jpg\n",
      "29_100.jpg\n",
      "30_100.jpg\n",
      "31_100.jpg\n",
      "33_100.jpg\n",
      "34_100.jpg\n",
      "36_100.jpg\n",
      "37_100.jpg\n",
      "38_100.jpg\n",
      "39_100.jpg\n",
      "40_100.jpg\n",
      "41_100.jpg\n",
      "42_100.jpg\n",
      "43_100.jpg\n",
      "45_100.jpg\n",
      "57_100.jpg\n",
      "r_177_100.jpg\n",
      "r_178_100.jpg\n",
      "r_179_100.jpg\n",
      "r_180_100.jpg\n",
      "r_181_100.jpg\n",
      "r_182_100.jpg\n",
      "r_183_100.jpg\n",
      "r_184_100.jpg\n",
      "r_185_100.jpg\n",
      "r_186_100.jpg\n",
      "r_187_100.jpg\n"
     ]
    }
   ],
   "source": [
    "with open('vect_feats_test.csv', 'w') as out:\n",
    "    k=0\n",
    "    for root, dirs, files in os.walk(\"test\"):\n",
    "        for f in files :\n",
    "            print(f)            \n",
    "            img = cv2.imread('test/'+f)\n",
    "            #img = cv2.resize(img, None, fx = 0.1, fy = 0.1)\n",
    "            feats = getFeatures(img, 50)\n",
    "            feats = np.concatenate([[f],feats])\n",
    "            out.write('%s\\n'% ','.join(feats))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"vect_feats_test.csv\", sep = ',').to_numpy()\n",
    "names_valid = data2[:,1]\n",
    "\n",
    "X_test = data2[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 49)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Apple Braeburn', 2: 'Apricot', 3: 'Avocado', 4: 'Banana'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes= {}\n",
    "k=1\n",
    "for i in os.listdir('training'):\n",
    "    classes[k]=i\n",
    "    k+=1\n",
    "classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred\n",
    "names = os.listdir('test')\n",
    "out = open('EL_MALLAHI_IMAD1.csv','w')\n",
    "out.write('nom_image,classe_predite\\n')\n",
    "\n",
    "\n",
    "for i in range(len(Y_pred)):\n",
    "    out.write('%s,%s\\n'%(data2[i,0],classes[Y_pred[i]]))\n",
    "    \n",
    "out.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
